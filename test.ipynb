{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 找不到指定的程序。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "from word2number import w2n\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from transformers import ViltProcessor, ViltForQuestionAnswering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`split.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"questions_shape.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "total_samples = len(lines)\n",
    "train_samples = int(0.7 * total_samples)\n",
    "val_samples = int(0.1 * total_samples)\n",
    "test_samples = total_samples - train_samples - val_samples\n",
    "\n",
    "\n",
    "random.shuffle(lines)\n",
    "\n",
    "\n",
    "train_data = lines[:train_samples]\n",
    "val_data = lines[train_samples:train_samples + val_samples]\n",
    "test_data = lines[train_samples + val_samples:]\n",
    "\n",
    "with open(\"train_data.txt\", \"w\") as file:\n",
    "    file.writelines(train_data)\n",
    "\n",
    "with open(\"val_data.txt\", \"w\") as file:\n",
    "    file.writelines(val_data)\n",
    "\n",
    "with open(\"test_data.txt\", \"w\") as file:\n",
    "    file.writelines(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`test_vilt.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n",
    "model = ViltForQuestionAnswering.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fine_tune.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_loader(file_path, batch_size=32):\n",
    "    batch_images = []\n",
    "    batch_questions = []\n",
    "    batch_labels = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(',')\n",
    "            if len(parts) == 4:\n",
    "                question = parts[1]\n",
    "                answer = parts[2]\n",
    "                image_path = parts[3]\n",
    "\n",
    "                try:\n",
    "                    img = Image.open(image_path).resize((384, 384))\n",
    "                    batch_images.append(img)\n",
    "                    batch_questions.append(question)\n",
    "                    ans1 = w2n.word_to_num(answer)\n",
    "                    batch_labels.append(str(ans1))\n",
    "\n",
    "                    if len(batch_images) == batch_size:\n",
    "                        yield batch_images, batch_questions, batch_labels\n",
    "                        batch_images, batch_questions, batch_labels = [], [], []\n",
    "                except IOError:\n",
    "                    print(f\"Error opening image {image_path}\")\n",
    "        if batch_images:  # Yield any remaining data as the last batch\n",
    "            yield batch_images, batch_questions, batch_labels\n",
    "\n",
    "\n",
    "def process_and_predict(images, questions):\n",
    "\n",
    "    encoding = processor(images, questions, return_tensors=\"pt\", padding=True)\n",
    "    outputs = model(**encoding)\n",
    "    return outputs\n",
    "\n",
    "def valid(model, best_acc):\n",
    "    print(\"--------------------this is validation------------------------\")\n",
    "    accuracy = []\n",
    "    model.cpu()\n",
    "    model.eval()\n",
    "    for images, questions, labels in batch_loader('data/val_data.txt'):#ata/val_data\n",
    "        outputs = process_and_predict(images, questions)\n",
    "        print(outputs.logits)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=1)\n",
    "        max_prob_indices = torch.argmax(probabilities, dim=1)\n",
    "        word_list = []\n",
    "        for i,k in  enumerate(max_prob_indices):\n",
    "            print(questions[i])\n",
    "            print(\"-------------ground truth --------------\")\n",
    "            print(labels[i])\n",
    "            print(\"-------------our answer --------------\")\n",
    "            print(model.config.id2label[int(k)])\n",
    "            word_list.append(model.config.id2label[int(k)])\n",
    "        matches = sum(1 for x, y in zip(word_list, labels) if x == y)\n",
    "        probability = matches / len(labels)\n",
    "        print(\"-------------batch accuracy --------------\")\n",
    "        accuracy.append(probability)\n",
    "        print(probability)\n",
    "\n",
    "    average = sum(accuracy) / len(accuracy)\n",
    "    print(\"-------------average accuracy --------------\")\n",
    "    print(average)\n",
    "    if average> best_acc:\n",
    "        best_acc = average\n",
    "        save_path = \"checkpoint/\" \n",
    "        model.save_pretrained(save_path)\n",
    "        print(\"save in:{save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ViltProcessor.from_pretrained(\"/data/ryh/xianyu/vilt/\")\n",
    "model = ViltForQuestionAnswering.from_pretrained(\"/data/ryh/xianyu/vilt/\")#.cuda()\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      3\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m      4\u001b[0m     train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    avg_train_loss = []\n",
    "    avg_train_acc = []\n",
    "    num = 0\n",
    "\n",
    "    for images, questions, labels in batch_loader('data/train_data.txt', batch_size=32):\n",
    "        \n",
    "        #image_list = [transforms.ToTensor()(image) for image in images]\n",
    "        label_list = [model.config.label2id[label] for label in labels]\n",
    "        labels_tensor = torch.tensor(label_list)#.cuda()\n",
    "        \n",
    "        encoding = processor(images, questions, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        for feature, data in encoding.data.items():\n",
    "            encoding.data[feature] = data#.cuda()\n",
    "\n",
    "        outputs = model(**encoding)\n",
    "        logits = outputs.logits\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(logits, labels_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        num += len(labels)\n",
    "       \n",
    "        train_loss += loss.item() * len(labels)\n",
    "        ret, predictions = torch.max(logits.data, 1)\n",
    "        correct_counts = predictions.eq(labels_tensor.data.view_as(predictions))\n",
    "        acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "        train_acc += acc.item() * len(labels)\n",
    "        \n",
    "        avg_train_loss.append(train_loss)\n",
    "        avg_train_acc.append(train_acc)\n",
    "        \n",
    "    avg_train_loss1 = sum(avg_train_loss) / num\n",
    "    avg_train_acc1 = sum(avg_train_acc) / num\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Average Training Loss: {avg_train_loss1}, Average Training Accuracy: {avg_train_acc1}\")\n",
    "    best_acc=0\n",
    "    valid(model, best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`test.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "\n",
    "for images, questions, labels in batch_loader('data/test_data.txt'):\n",
    "    outputs = process_and_predict(images, questions)\n",
    "    print(outputs.logits)\n",
    "\n",
    "    probabilities = torch.softmax(outputs.logits, dim=1)\n",
    "    max_prob_indices = torch.argmax(probabilities, dim=1)\n",
    "    word_list = []\n",
    "\n",
    "    for i,k in  enumerate(max_prob_indices):\n",
    "        print(questions[i])\n",
    "        print(\"-------------ground truth --------------\")\n",
    "        print(labels[i])\n",
    "        print(\"-------------our answer --------------\")\n",
    "        print(model.config.id2label[int(k)])\n",
    "        word_list.append(model.config.id2label[int(k)])\n",
    "\n",
    "    matches = sum(1 for x, y in zip(word_list, labels) if x == y)\n",
    "    probability = matches / len(labels)\n",
    "    print(\"-------------batch accuracy --------------\")\n",
    "    accuracy.append(probability)\n",
    "    print(probability)\n",
    "\n",
    "average = sum(accuracy) / len(accuracy)\n",
    "print(\"-------------average accuracy --------------\")\n",
    "print(average)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
